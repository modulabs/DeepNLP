{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime \n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils.data_utils import get_file\n",
    "\n",
    "# from tensorflow.python.keras._impl.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# from tensorflow.python.keras._impl.keras.layers import Embedding\n",
    "# from tensorflow.python.keras._impl.keras.layers import Reshape, Flatten, Dropout, Concatenate, dot, add\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial global var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 미리 Global 변수를 지정하자. 파일 명, 파일 위치, 디렉토리 등이 있다.\n",
    "\n",
    "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
    "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
    "DATA_PATH = './data/'\n",
    "\n",
    "## 학습에 필요한 파라메터들에 대해서 지정하는 부분이다.\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 50\n",
    "HIDDEN = 64\n",
    "BUFFER_SIZE = 2048\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "EMBEDDING_DIM = 128\n",
    "MAX_SEQ_LEN = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 불러오는 부분이다. 효과적인 데이터 불러오기를 위해, 미리 넘파이 형태로 저장시킨 데이터를 로드한다.\n",
    "\n",
    "q1_data = np.load(open(DATA_PATH + Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(DATA_PATH + Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(DATA_PATH + LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "\n",
    "with open(DATA_PATH + NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    prepro_configs = json.load(f)\n",
    "\n",
    "# ## 미리 저장한 임베딩 값을 불러오자\n",
    "# word_embedding_matrix = np.load(open(DATA_PATH+WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "# with open(DATA_PATH+NB_WORDS_DATA_FILE, 'r') as f:\n",
    "#     nb_words = json.load(f)['nb_words']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 나누어 저장하자. sklearn의 train_test_split을 사용하면 유용하다. 하지만, 쿼라 데이터의 경우는\n",
    "## 입력이 1개가 아니라 2개이다. 따라서, np.stack을 사용하여 두개를 하나로 쌓은다음 활용하여 분류한다.\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1) \n",
    "y = labels\n",
    "\n",
    "# X = word_embedding_matrix[X[:1000]]\n",
    "# y = y[:1000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "\n",
    "#     # Build the embedding matrix\n",
    "#     for word, index in vocabs.items():\n",
    "#         if word in word2vec.vocab:\n",
    "#             embeddings[index] = word2vec.word_vec(word)\n",
    "#     del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(q, sim_q, labels):\n",
    "    features = {\"q\": q, \"sim_q\": sim_q}\n",
    "    return features, labels\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((Q1_train, Q2_train, y_train))\n",
    "    dataset = dataset.shuffle(buffer_size=len(Q1_train))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((Q1_test, Q2_test, y_test))\n",
    "    dataset = dataset.shuffle(buffer_size=len(Q1_test))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Malstm(features, labels, mode, params):\n",
    "    \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    labels = tf.to_float(tf.reshape(labels, [-1,1]))\n",
    "\n",
    "    q1 = tf.contrib.layers.embed_sequence(\n",
    "                                            features['q'],\n",
    "                                            VOCAB_SIZE,\n",
    "                                            EMBEDDING_DIM,\n",
    "                                            initializer=params['embed_init']\n",
    "                                            )\n",
    "\n",
    "    q2 = tf.contrib.layers.embed_sequence(\n",
    "                                            features['sim_q'],\n",
    "                                            VOCAB_SIZE,\n",
    "                                            EMBEDDING_DIM,\n",
    "                                            initializer=params['embed_init']\n",
    "                                            )\n",
    "    \n",
    "#     with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "#         glove_weights_initializer = tf.constant_initializer(word_embedding_matrix)\n",
    "#         embedding_weights = tf.get_variable(\n",
    "#             name='embedding_weights',\n",
    "#             initializer = glove_weights_initializer,\n",
    "#             shape=(nb_words+1, EMBEDDING_DIM), \n",
    "#             trainable=False)\n",
    "\n",
    "#         q1 = tf.nn.embedding_lookup(embedding_weights, features['q'])\n",
    "#         q2 = tf.nn.embedding_lookup(embedding_weights, features['sim_q'])\n",
    "            \n",
    "    with tf.variable_scope('q_bi_lstm'):\n",
    "        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "        _, output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw = lstm_fw_cell,\n",
    "                                                          cell_bw = lstm_bw_cell,\n",
    "                                                          inputs = q1,\n",
    "                                                          dtype = tf.float32)\n",
    "\n",
    "        q_final_state = tf.concat([output_states[0].h, output_states[1].h], axis=1)\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope('sim_bi_lstm'):\n",
    "        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(num_units = HIDDEN, activation = tf.nn.tanh)\n",
    "        _, output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw = lstm_fw_cell,\n",
    "                                                          cell_bw = lstm_bw_cell,\n",
    "                                                          inputs = q2,\n",
    "                                                          dtype = tf.float32)\n",
    "        \n",
    "        sim_final_state = tf.concat([output_states[0].h, output_states[1].h], axis=1)\n",
    "                \n",
    "    with tf.variable_scope('output_layer'):\n",
    "        #Malstm\n",
    "        output = K.exp(-K.sum(K.abs(q_final_state -  sim_final_state), axis=1, keepdims=True))\n",
    "            \n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        loss = tf.keras.backend.binary_crossentropy(\n",
    "            labels,\n",
    "            output,\n",
    "            from_logits=False\n",
    "        )\n",
    "        \n",
    "#         loss = tf.losses.mean_squared_error(labels, output)\n",
    "#         loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.one_hot(labels, depth=2),\n",
    "#                                                logits = output\n",
    "#                                               )\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(1e-4).minimize(loss, global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss = loss)\n",
    "    \n",
    "    elif EVAL:\n",
    "        loss = tf.losses.mean_squared_error(labels, output)\n",
    "        pred = tf.nn.sigmoid(output)\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(pred))\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc': accuracy})\n",
    "        \n",
    "    elif PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\n",
    "                'prob': cos_sim,\n",
    "                'q_sem': q_dense_layer,\n",
    "                'sim_q_sem': sim_q_dense_layer\n",
    "            }\n",
    "        )\n",
    "    \n",
    "params = {'embed_init': tf.random_uniform_initializer(-1.0, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"data/checkpoint/\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "config_tf = tf.estimator.RunConfig()\n",
    "config_tf._save_checkpoints_steps = 100\n",
    "config_tf._save_checkpoints_secs = None\n",
    "config_tf._keep_checkpoint_max =  2\n",
    "config_tf._log_step_count_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started at 10:04:50\n",
      ".......................................\n",
      "1.10.1\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/sinseongjin/github/DeepNLP/7.NLPBOOK/6.TEXT_SIM/data/checkpoint/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x138487780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sinseongjin/github/DeepNLP/7.NLPBOOK/6.TEXT_SIM/data/checkpoint/model.ckpt-0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n\nCaused by op 'save/Assign_32', defined at:\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-82-16631460ab99>\", line 15, in <module>\n    dssm_est.train(train_input_fn, steps=EPOCH)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n    saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1448, in _train_with_estimator_spec\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 421, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 832, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 555, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1018, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1023, in _create_session\n    return self._sess_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 712, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 474, in create_session\n    self._scaffold.finalize()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 772, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1725\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n\nCaused by op 'save/Assign_32', defined at:\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-82-16631460ab99>\", line 15, in <module>\n    dssm_est.train(train_input_fn, steps=EPOCH)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n    saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1448, in _train_with_estimator_spec\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 421, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 832, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 555, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1018, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1023, in _create_session\n    return self._sess_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 712, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 474, in create_session\n    self._scaffold.finalize()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 772, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-16631460ab99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdssm_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMalstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdssm_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# tf.estimator.train_and_evaluate(dssm_est, train_spec, eval_spec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m   return MonitoredSession(session_creator=session_creator, hooks=all_hooks,\n\u001b[0;32m--> 421\u001b[0;31m                           stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    830\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    831\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \"\"\"\n\u001b[1;32m   1017\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Loads the checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1757\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1759\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n\nCaused by op 'save/Assign_32', defined at:\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-82-16631460ab99>\", line 15, in <module>\n    dssm_est.train(train_input_fn, steps=EPOCH)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n    saving_listeners)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1448, in _train_with_estimator_spec\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 421, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 832, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 555, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1018, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1023, in _create_session\n    return self._sess_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 712, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 474, in create_session\n    self._scaffold.finalize()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 772, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/sinseongjin/tf110/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [192,256] rhs shape= [114,256]\n\t [[Node: save/Assign_32 = Assign[T=DT_FLOAT, _class=[\"loc:@sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sim_bi_lstm/bidirectional_rnn/fw/basic_lstm_cell/kernel/Adam_1, save/RestoreV2:32)]]\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# validation_monitor = tf.contrib\n",
    "\n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)\n",
    "\n",
    "# train_spec = tf.estimator.TrainSpec(train_input_fn)\n",
    "# eval_spec = tf.estimator.EvalSpec(test_input_fn)\n",
    "\n",
    "dssm_est = tf.estimator.Estimator(Malstm, model_dir=model_dir, config=config_tf, params=params)\n",
    "dssm_est.train(train_input_fn, steps=EPOCH)\n",
    "\n",
    "# tf.estimator.train_and_evaluate(dssm_est, train_spec, eval_spec)\n",
    "\n",
    "# For prediction or extract values\n",
    "# prediction = est.predict(eval_input_fn)\n",
    "\n",
    "# for i, p in enumerate(prediction):\n",
    "#     print(i, p['sim_q_sem'])\n",
    "\n",
    "time_end = datetime.now()\n",
    "\n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR_PATH = './'\n",
    "Q1_TEST_DATA_FILE = 'q1_test.npy'\n",
    "Q2_TEST_DATA_FILE = 'q2_test.npy'\n",
    "\n",
    "test_q1_data = np.load(open(FILE_DIR_PATH + Q1_TEST_DATA_FILE, 'rb'))\n",
    "test_q2_data = np.load(open(FILE_DIR_PATH + Q2_TEST_DATA_FILE, 'rb'))\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"q\":test_q1_data, \n",
    "                                                         \"sim_q\":test_q2_data}, \n",
    "                                                      shuffle=False)\n",
    "\n",
    "predictions = np.array([p['prob'] for p in est.predict(input_fn=\n",
    "predict_input_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy\n",
    "\n",
    "p = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "logit_q = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "q = tf.nn.sigmoid(logit_q)\n",
    "\n",
    "feed_dict = {\n",
    "  p: [[0, 0, 0, 1, 0],\n",
    "      [1, 0, 0, 0, 0]],\n",
    "  logit_q: [[0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "            [0.3, 0.3, 0.2, 0.1, 0.1]]\n",
    "}\n",
    "\n",
    "prob1 = -p * tf.log(q)\n",
    "# prob2 = p * -tf.log(q) + (1 - p) * -tf.log(1 - q)\n",
    "# prob3 = p * -tf.log(tf.sigmoid(logit_q)) + (1-p) * -tf.log(1-tf.sigmoid(logit_q))\n",
    "# prob4 = tf.nn.sigmoid_cross_entropy_with_logits(labels=p, logits=logit_q)\n",
    "print(prob1.eval(feed_dict))\n",
    "# print(prob2.eval(feed_dict))\n",
    "# print(prob3.eval(feed_dict))\n",
    "# print(prob4.eval(feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/bradleypallen/keras-quora-question-pairs/blob/master/quora-question-pairs-data-prep.ipynb\n",
    "https://github.com/Smerity/keras_snli\n",
    "https://github.com/bradleypallen/keras-quora-question-pairs/blob/master/quora-question-pairs-training-attention.ipynb\n",
    "https://github.com/bradleypallen/keras-quora-question-pairs/blob/master/quora-question-pairs-training.ipynb\n",
    "http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
